{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc64595d-7785-483c-9e64-39535825ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a89a38-523d-475a-8a2c-63c6a4b67472",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(os.getcwd()).parent\n",
    "\n",
    "data_path = os.path.join(MAIN_DIR, 'datasets', 'NYC_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45aad942-e2d3-4483-8630-e458f0d57527",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month = \"2023\", \"february\" ### Change year and month on your choice\n",
    "parquet_file = os.path.join(data_path, year, f\"{year}-{month}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2a05f-8999-48e9-80ba-a2573adfb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(parquet_file, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869da3d3-fe66-44c0-a247-d96fe073d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet_snippet(parquet_file: str, table_name: str) -> None:\n",
    "    df = pd.read_parquet(parquet_file, engine=\"pyarrow\")\n",
    "    data = df.to_dict(orient=\"records\")\n",
    "\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=\"green_taxi_pipeline\",\n",
    "        destination=\"duckdb\",\n",
    "        dataset_name=\"green_trip\",\n",
    "    )\n",
    "    load_info = pipeline.run(data, table_name=table_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a164a2-d43c-433e-aad8-171a681b8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_snippet(parquet_file, \"february_2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d65ce9-f17e-412e-bccc-86e853d1885e",
   "metadata": {},
   "source": [
    "### Seeing what DuckDB container has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a56d6d9-d3d4-4a7f-aeda-ca84525a0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ february_2023       │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = duckdb.connect(\"green_taxi_pipeline.duckdb\")\n",
    "\n",
    "# let's see the tables\n",
    "conn.sql(\"SET search_path = 'green_trip'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"show tables\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a591d43-3852-4b83-9d82-341a8a372c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " february_2023 table below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>ratecode_id</th>\n",
       "      <th>pu_location_id</th>\n",
       "      <th>do_location_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 00:46:22+00:00</td>\n",
       "      <td>2023-02-01 01:05:57+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>42.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>F7qsGhJOtlCK7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:05:09+00:00</td>\n",
       "      <td>2023-02-01 00:22:42+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>O7CMHA/zq4BTJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:03:47+00:00</td>\n",
       "      <td>2023-02-01 00:27:30+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.32</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>1mcP+edjRIcXSQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:30:56+00:00</td>\n",
       "      <td>2023-01-31 23:51:40+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>ZhZRY8EgJURVmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:15:05+00:00</td>\n",
       "      <td>2023-02-01 00:26:02+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>X1+J0dB5xH2Ysg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 11:49:12+00:00</td>\n",
       "      <td>2023-02-02 12:19:37+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196</td>\n",
       "      <td>237</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>35.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>v9h7T/xKRnm3Ww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-02 11:07:34+00:00</td>\n",
       "      <td>2023-02-02 11:36:58+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.68</td>\n",
       "      <td>49.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>wP5XthZZOXSANg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-02 11:57:38+00:00</td>\n",
       "      <td>2023-02-02 12:09:16+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>ljXrGOrbdM+uHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-02 11:54:28+00:00</td>\n",
       "      <td>2023-02-02 12:01:06+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260</td>\n",
       "      <td>129</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>ib2RAa+QDCiT0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-02 12:02:42+00:00</td>\n",
       "      <td>2023-02-02 12:36:28+00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.45</td>\n",
       "      <td>47.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1707590001.079537</td>\n",
       "      <td>Vh4sUzQ31RbMSw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vendor_id      lpep_pickup_datetime     lpep_dropoff_datetime  \\\n",
       "0             1 2023-02-01 00:46:22+00:00 2023-02-01 01:05:57+00:00   \n",
       "1             2 2023-02-01 00:05:09+00:00 2023-02-01 00:22:42+00:00   \n",
       "2             2 2023-02-01 00:03:47+00:00 2023-02-01 00:27:30+00:00   \n",
       "3             2 2023-01-31 23:30:56+00:00 2023-01-31 23:51:40+00:00   \n",
       "4             2 2023-02-01 00:15:05+00:00 2023-02-01 00:26:02+00:00   \n",
       "...         ...                       ...                       ...   \n",
       "2995          1 2023-02-02 11:49:12+00:00 2023-02-02 12:19:37+00:00   \n",
       "2996          2 2023-02-02 11:07:34+00:00 2023-02-02 11:36:58+00:00   \n",
       "2997          2 2023-02-02 11:57:38+00:00 2023-02-02 12:09:16+00:00   \n",
       "2998          2 2023-02-02 11:54:28+00:00 2023-02-02 12:01:06+00:00   \n",
       "2999          2 2023-02-02 12:02:42+00:00 2023-02-02 12:36:28+00:00   \n",
       "\n",
       "     store_and_fwd_flag  ratecode_id  pu_location_id  do_location_id  \\\n",
       "0                     N          1.0              74             265   \n",
       "1                     N          1.0             216             196   \n",
       "2                     N          1.0               7             114   \n",
       "3                     N          1.0              74             239   \n",
       "4                     N          1.0              82             223   \n",
       "...                 ...          ...             ...             ...   \n",
       "2995                  N          1.0             196             237   \n",
       "2996                  N          1.0             166              95   \n",
       "2997                  N          1.0              75              75   \n",
       "2998                  N          1.0             260             129   \n",
       "2999                  N          1.0             127             170   \n",
       "\n",
       "      passenger_count  trip_distance  fare_amount  ...  mta_tax  tip_amount  \\\n",
       "0                 1.0          10.80         42.9  ...      1.5        0.00   \n",
       "1                 1.0           4.76         23.3  ...      0.5        0.00   \n",
       "2                 1.0           6.32         30.3  ...      0.5        8.89   \n",
       "3                 1.0           3.50         16.3  ...      0.5        0.00   \n",
       "4                 1.0           3.14         17.0  ...      0.5        0.00   \n",
       "...               ...            ...          ...  ...      ...         ...   \n",
       "2995              2.0           7.30         35.9  ...      1.5        2.50   \n",
       "2996              1.0          11.68         49.9  ...      0.5        5.00   \n",
       "2997              1.0           1.04         10.7  ...      0.5        0.00   \n",
       "2998              3.0           0.83          7.9  ...      0.5        1.88   \n",
       "2999              1.0          10.45         47.8  ...      0.5        0.00   \n",
       "\n",
       "      tolls_amount  improvement_surcharge  total_amount  payment_type  \\\n",
       "0             0.00                    1.0         45.40           2.0   \n",
       "1             0.00                    1.0         25.80           2.0   \n",
       "2             0.00                    1.0         44.44           1.0   \n",
       "3             0.00                    1.0         21.55           2.0   \n",
       "4             0.00                    1.0         19.50           2.0   \n",
       "...            ...                    ...           ...           ...   \n",
       "2995          0.00                    1.0         42.65           1.0   \n",
       "2996          6.55                    1.0         62.95           1.0   \n",
       "2997          0.00                    1.0         12.20           2.0   \n",
       "2998          0.00                    1.0         11.28           1.0   \n",
       "2999          0.00                    1.0         52.05           2.0   \n",
       "\n",
       "      trip_type  congestion_surcharge       _dlt_load_id         _dlt_id  \n",
       "0           1.0                  0.00  1707590001.079537  F7qsGhJOtlCK7g  \n",
       "1           1.0                  0.00  1707590001.079537  O7CMHA/zq4BTJA  \n",
       "2           1.0                  2.75  1707590001.079537  1mcP+edjRIcXSQ  \n",
       "3           1.0                  2.75  1707590001.079537  ZhZRY8EgJURVmA  \n",
       "4           1.0                  0.00  1707590001.079537  X1+J0dB5xH2Ysg  \n",
       "...         ...                   ...                ...             ...  \n",
       "2995        1.0                  2.75  1707590001.079537  v9h7T/xKRnm3Ww  \n",
       "2996        1.0                  0.00  1707590001.079537  wP5XthZZOXSANg  \n",
       "2997        1.0                  0.00  1707590001.079537  ljXrGOrbdM+uHA  \n",
       "2998        1.0                  0.00  1707590001.079537  ib2RAa+QDCiT0g  \n",
       "2999        1.0                  2.75  1707590001.079537  Vh4sUzQ31RbMSw  \n",
       "\n",
       "[3000 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and the data\n",
    "\n",
    "print(\"\\n\\n\\n february_2023 table below:\")\n",
    "\n",
    "rides = conn.sql(\"\"\"\n",
    "    SELECT * FROM february_2023 \n",
    "    LIMIT 3000      \n",
    "                 \"\"\").df()\n",
    "display(rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da912d-a42a-4b5e-9957-a7026d4de730",
   "metadata": {},
   "source": [
    "Notice that all uppercase character on each column has been turned to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf6d1ec-11ed-4a3d-80e1-f8d16f0e66e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype                  \n",
      "---  ------                 --------------  -----                  \n",
      " 0   vendor_id              3000 non-null   int64                  \n",
      " 1   lpep_pickup_datetime   3000 non-null   datetime64[us, Etc/UTC]\n",
      " 2   lpep_dropoff_datetime  3000 non-null   datetime64[us, Etc/UTC]\n",
      " 3   store_and_fwd_flag     3000 non-null   object                 \n",
      " 4   ratecode_id            3000 non-null   float64                \n",
      " 5   pu_location_id         3000 non-null   int64                  \n",
      " 6   do_location_id         3000 non-null   int64                  \n",
      " 7   passenger_count        3000 non-null   float64                \n",
      " 8   trip_distance          3000 non-null   float64                \n",
      " 9   fare_amount            3000 non-null   float64                \n",
      " 10  extra                  3000 non-null   float64                \n",
      " 11  mta_tax                3000 non-null   float64                \n",
      " 12  tip_amount             3000 non-null   float64                \n",
      " 13  tolls_amount           3000 non-null   float64                \n",
      " 14  improvement_surcharge  3000 non-null   float64                \n",
      " 15  total_amount           3000 non-null   float64                \n",
      " 16  payment_type           3000 non-null   float64                \n",
      " 17  trip_type              3000 non-null   float64                \n",
      " 18  congestion_surcharge   3000 non-null   float64                \n",
      " 19  _dlt_load_id           3000 non-null   object                 \n",
      " 20  _dlt_id                3000 non-null   object                 \n",
      "dtypes: datetime64[us, Etc/UTC](2), float64(13), int64(3), object(3)\n",
      "memory usage: 492.3+ KB\n"
     ]
    }
   ],
   "source": [
    "rides.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8af67-e735-4efa-9b37-5e393d086d62",
   "metadata": {},
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736674c4-e3b2-47cb-94ad-dc32d89c54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlt.sources.helpers import requests\n",
    "\n",
    "# Specify the URL of the API endpoint\n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\"\n",
    "\n",
    "# Make a request and check if it was successful\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db1f1a71-c6dc-4a47-8569-5a1e00425623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d44908-b8b7-47a7-af0e-3b0c4e8a8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet(url, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e3eed7c-d761-4598-9d66-ebaf3e69d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72039</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:33:00</td>\n",
       "      <td>2023-03-31 23:45:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.93</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72040</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:27:00</td>\n",
       "      <td>2023-03-31 23:53:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.49</td>\n",
       "      <td>34.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72041</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:09:00</td>\n",
       "      <td>2023-03-31 23:40:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.27</td>\n",
       "      <td>41.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>6.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72042</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:39:00</td>\n",
       "      <td>2023-04-01 00:01:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.42</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72043</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:38:00</td>\n",
       "      <td>2023-03-31 23:53:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>16.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "72039         2  2023-03-31 23:33:00   2023-03-31 23:45:00               None   \n",
       "72040         2  2023-03-31 23:27:00   2023-03-31 23:53:00               None   \n",
       "72041         2  2023-03-31 23:09:00   2023-03-31 23:40:00               None   \n",
       "72042         2  2023-03-31 23:39:00   2023-04-01 00:01:00               None   \n",
       "72043         2  2023-03-31 23:38:00   2023-03-31 23:53:00               None   \n",
       "\n",
       "       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "72039         NaN            25           144              NaN           2.93   \n",
       "72040         NaN            36           236              NaN           8.49   \n",
       "72041         NaN            42           225              NaN          12.27   \n",
       "72042         NaN            80           189              NaN           4.42   \n",
       "72043         NaN           256            66              NaN           2.96   \n",
       "\n",
       "       fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "72039        16.46    0.0      0.0        4.04          0.00        NaN   \n",
       "72040        34.66    0.0      0.0        7.68          0.00        NaN   \n",
       "72041        41.79    0.0      0.0        7.40          6.55        NaN   \n",
       "72042        17.82    0.0      0.0        1.94          0.00        NaN   \n",
       "72043        16.42    0.0      0.0        1.00          0.00        NaN   \n",
       "\n",
       "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "72039                    1.0         24.25           NaN        NaN   \n",
       "72040                    1.0         46.09           NaN        NaN   \n",
       "72041                    1.0         56.74           NaN        NaN   \n",
       "72042                    1.0         20.76           NaN        NaN   \n",
       "72043                    1.0         18.42           NaN        NaN   \n",
       "\n",
       "       congestion_surcharge  \n",
       "72039                   NaN  \n",
       "72040                   NaN  \n",
       "72041                   NaN  \n",
       "72042                   NaN  \n",
       "72043                   NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ddfd72-9605-4c33-b4fe-ca86a2047103",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"green_taxi_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"green_trip\",\n",
    ")\n",
    "# The response contains a list of issues\n",
    "load_info = pipeline.run(df2.to_dict(orient=\"records\"), table_name=\"march_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d433563-6659-4e28-8f86-3db814408b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline green_taxi_pipeline load step completed in 9.97 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset green_trip\n",
      "The duckdb destination used duckdb:////workspaces/DataEngineering_UK_house_price/Notebooks/green_taxi_pipeline.duckdb location to store data\n",
      "Load package 1707592563.9933667 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1ddc3c-f652-49fc-81e2-43877b81c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ february_2023       │\n",
       "│ march_2023          │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the tables\n",
    "conn.sql(\"SET search_path = 'green_trip'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"show tables\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b24db-3762-4388-83ab-794c55093524",
   "metadata": {},
   "source": [
    "### Load data to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f06a1f1e-d2fe-492f-bc4d-bcfa6fcb87da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/__init__.py:108: Dlt04DeprecationWarning: The `credentials argument` to pipeline is deprecated and will be removed in a future version. Pass the same credentials to the `destination` instance instead, e.g. pipeline(destination=dlt.destinations.postgres(credentials=...)). Deprecated in dlt 0.4.0 to be removed in 0.5.0.\n",
      "  credentials_argument_deprecated(\"pipeline\", credentials, destination)\n"
     ]
    }
   ],
   "source": [
    "pipeline_postgres = dlt.pipeline(\n",
    "    pipeline_name='pipeline_postgres', \n",
    "    destination='postgres', \n",
    "    dataset_name='green_trip', \n",
    "    credentials=\"postgresql://postgres:postgres@localhost:5432/postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6d99489-9881-488c-a6ea-5ded111a3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:54:02,892|[ERROR                ]|27727|140450161231616|dlt|load.py|w_spool_job:170|Temporary problem when adding job 1707594842.435166/new_jobs/march_2023.65a169255b.0.parquet\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.0.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.0.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "2024-02-10 19:54:02,937|[WARNING              ]|27727|140450929480320|dlt|load.py|complete_jobs:307|Job for march_2023.65a169255b.parquet retried in load 1707594842.435166 with message Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.0.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.0.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "2024-02-10 19:54:03,068|[ERROR                ]|27727|140450161231616|dlt|load.py|w_spool_job:170|Temporary problem when adding job 1707594842.435166/new_jobs/march_2023.65a169255b.1.parquet\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.1.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.1.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "2024-02-10 19:54:03,084|[WARNING              ]|27727|140450929480320|dlt|load.py|complete_jobs:307|Job for march_2023.65a169255b.parquet retried in load 1707594842.435166 with message Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.1.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.1.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "2024-02-10 19:54:03,215|[ERROR                ]|27727|140450161231616|dlt|load.py|w_spool_job:170|Temporary problem when adding job 1707594842.435166/new_jobs/march_2023.65a169255b.2.parquet\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.2.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.2.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "2024-02-10 19:54:03,231|[WARNING              ]|27727|140450929480320|dlt|load.py|complete_jobs:307|Job for march_2023.65a169255b.parquet retried in load 1707594842.435166 with message Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.2.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.2.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "2024-02-10 19:54:03,361|[ERROR                ]|27727|140450161231616|dlt|load.py|w_spool_job:170|Temporary problem when adding job 1707594842.435166/new_jobs/march_2023.65a169255b.3.parquet\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.3.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.3.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "2024-02-10 19:54:03,378|[WARNING              ]|27727|140450929480320|dlt|load.py|complete_jobs:307|Job for march_2023.65a169255b.parquet retried in load 1707594842.435166 with message Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.3.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.3.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "2024-02-10 19:54:03,508|[ERROR                ]|27727|140450161231616|dlt|load.py|w_spool_job:170|Temporary problem when adding job 1707594842.435166/new_jobs/march_2023.65a169255b.4.parquet\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.4.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.4.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "2024-02-10 19:54:03,525|[WARNING              ]|27727|140450929480320|dlt|load.py|complete_jobs:307|Job for march_2023.65a169255b.parquet retried in load 1707594842.435166 with message Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 219, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 129, in execute_query\n",
      "    raise outer\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 124, in execute_query\n",
      "    self._conn.execute(query, db_args)\n",
      "duckdb.duckdb.Error: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.4.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py\", line 159, in w_spool_job\n",
      "    job = client.start_file_load(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 162, in start_file_load\n",
      "    job = DuckDbCopyJob(table[\"name\"], file_path, self.sql_client)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/duck.py\", line 136, in __init__\n",
      "    sql_client.execute_sql(\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/impl/duckdb/sql_client.py\", line 108, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 221, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTransientException: Invalid Error: Failed to read file \"/home/codespace/.dlt/pipelines/green_taxi_pipeline/load/normalized/1707594842.435166/new_jobs/march_2023.65a169255b.4.parquet\" - column count mismatch: expected 22 columns but found 20\n",
      "\n"
     ]
    },
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage load when processing package 1707594842.435166 with exception:\n\n<class 'dlt.load.exceptions.LoadClientJobRetry'>\nJob for march_2023.65a169255b.parquet had 5 retries which a multiple of 5. Exiting retry loop. You can still rerun the load package to retry this job.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoadClientJobRetry\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:503\u001b[0m, in \u001b[0;36mPipeline.load\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m signals\u001b[38;5;241m.\u001b[39mdelayed_signals():\n\u001b[0;32m--> 503\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m info: LoadInfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_info(load_step)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py:88\u001b[0m, in \u001b[0;36mrun_pool\u001b[0;34m(config, run_f)\u001b[0m\n\u001b[1;32m     87\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning pool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43m_run_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# for next run\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     signals\u001b[38;5;241m.\u001b[39mraise_if_signalled()\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py:81\u001b[0m, in \u001b[0;36mrun_pool.<locals>._run_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run_f, Runnable):\n\u001b[0;32m---> 81\u001b[0m     run_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py:564\u001b[0m, in \u001b[0;36mLoad.run\u001b[0;34m(self, pool)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_info_start_load_id(load_id)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_single_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TRunMetrics(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_storage\u001b[38;5;241m.\u001b[39mlist_normalized_packages()))\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/load/load.py:526\u001b[0m, in \u001b[0;36mLoad.load_single_package\u001b[0;34m(self, load_id, schema)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m r_c \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m r_c \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mraise_on_max_retries \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 526\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m LoadClientJobRetry(\n\u001b[1;32m    527\u001b[0m                 load_id,\n\u001b[1;32m    528\u001b[0m                 new_job\u001b[38;5;241m.\u001b[39mjob_file_info\u001b[38;5;241m.\u001b[39mjob_id(),\n\u001b[1;32m    529\u001b[0m                 r_c,\n\u001b[1;32m    530\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mraise_on_max_retries,\n\u001b[1;32m    531\u001b[0m             )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mLoadClientJobRetry\u001b[0m: Job for march_2023.65a169255b.parquet had 5 retries which a multiple of 5. Exiting retry loop. You can still rerun the load package to retry this job.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m load_info_postgre \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarch_2023\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:629\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, schema_contract)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\n\u001b[1;32m    620\u001b[0m         data,\n\u001b[1;32m    621\u001b[0m         table_name\u001b[38;5;241m=\u001b[39mtable_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m         schema_contract\u001b[38;5;241m=\u001b[39mschema_contract,\n\u001b[1;32m    627\u001b[0m     )\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(loader_file_format\u001b[38;5;241m=\u001b[39mloader_file_format)\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:164\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# refresh live schemas in storage or import schema path\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[0;32m--> 164\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# save modified live schemas\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:151\u001b[0m, in \u001b[0;36mwith_state_sync.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_state(extract_state\u001b[38;5;241m=\u001b[39mshould_extract_state) \u001b[38;5;28;01mas\u001b[39;00m state:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# add the state to container as a context\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container\u001b[38;5;241m.\u001b[39minjectable_context(StateInjectableContext(state\u001b[38;5;241m=\u001b[39mstate)):\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:509\u001b[0m, in \u001b[0;36mPipeline.load\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m l_ex:\n\u001b[1;32m    508\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_info(load_step)\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_step\u001b[38;5;241m.\u001b[39mcurrent_load_id, l_ex, step_info\n\u001b[1;32m    511\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ml_ex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage load when processing package 1707594842.435166 with exception:\n\n<class 'dlt.load.exceptions.LoadClientJobRetry'>\nJob for march_2023.65a169255b.parquet had 5 retries which a multiple of 5. Exiting retry loop. You can still rerun the load package to retry this job."
     ]
    }
   ],
   "source": [
    "load_info_postgre = pipeline.run(df2.head(20), table_name=\"march_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa9fdc-ec1b-459d-a62e-5024cb567d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
